#!/usr/bin/env node
const cds = require('../index'), { local } = cds.utils
const crypto = require('crypto')
const COLORS = !!process.stdout.isTTY && !!process.stderr.isTTY && !process.env.NO_COLOR
const GREY = COLORS ? '\x1b[2m' : ''
const RESET = COLORS ? '\x1b[0m' : ''
const DEBUG = cds.debug('deploy')

/**
 * Implementation of `cds.deploy` common to all databases.
 * It uses the database-specific `db.deploy` to prepare the database, e.g.
 * deploy create tables and views in case of a SQL database, then fills
 * in initial data, if present.
 */
module.exports = exports = function cds_deploy (model,options,csvs) {
  return {
    /** @param {import('@sap/cds/lib/srv/srv-api')} db */
    async to(db, o = options || {}) {

      const TRACE = cds.debug('trace')
      TRACE?.time('cds.deploy db  ')

      if (!model) throw new Error('Must provide a model or a path to model, received: ' + model)
      if (model && !model.definitions) model = await cds.load(model).then(cds.minify)

      if (o.mocked) exports.include_external_entities_in(model)
      else exports.exclude_external_entities_in(model)

      if (!db.run) db = await cds.connect.to(db)
      if (!cds.db) cds.db = cds.services.db = db
      if (!db.model) db.model = model

      // eslint-disable-next-line no-console
      const LOG = o.silent || o.dry || !cds.log('deploy')._info ? () => {} : console.log
      const _deploy = async tx => {
        // create / update schema
        let any = await exports.create(tx, model, o)
        if (!any && !csvs) return db
        // fill in initial data
        await exports.init(tx, model, o, csvs, file => LOG(GREY, ` > init from ${local(file)}`, RESET))
      }

      let url = db.url4(cds.context?.tenant)
      if (url === ':memory:') url = 'in-memory database.'
      else if (!url.startsWith('http:')) url = local(url)
      try {
        await (o.dry ? _deploy(db) : db.run(_deploy))
        LOG('/> successfully deployed to', url, '\n')
      } catch (e) {
        LOG('/> deployment to', url, 'failed\n')
        throw e
      }

      TRACE?.timeEnd('cds.deploy db  ')
      return db
    },

    // continue to support cds.deploy() as well...
    then(n, e) {
      return this.to(cds.db || 'db').then(n, e)
    },
    catch(e) {
      return this.to(cds.db || 'db').catch(e)
    },
  }
}

exports.create = async function cds_deploy_create (db, csn=db.model, o) {

  /* eslint-disable no-console */

  if (!o.to || o.to === db.options.kind)  o = { ...db.options, ...o }
  if (o.impl === '@cap-js/sqlite') {
    // REVISIT: Move that to configuration or to cds.compile -> currently cds compile creates wrong output
    o.betterSqliteSessionVariables = true
    o.sqlDialect = 'sqlite'
  }

  let drops, creas
  let schevo = o.schema_evolution === 'auto' || o['with-auto-schema-evolution'] || o['model-only'] || o['delta-from'] || (o.kind === 'postgres' && o.schema_evolution !== false);
  if (schevo) {
    const { prior, table_exists } = await get_prior_model()
    const { afterImage, drops: d, createsAndAlters } = cds.compile.to.sql.delta(csn, o, prior);
    const after = JSON.stringify(afterImage)
    if (!o.dry && after != prior) {
      if (!table_exists) {
        const CLOB = o.dialect === 'postgres' || o.kind === 'postgres' ? 'text' : 'CLOB'
        await db.run(`CREATE table cds_model (csn ${CLOB})`)
        await db.run(`INSERT into cds_model values (?)`, after)
      } else {
        await db.run(`UPDATE cds_model SET csn = ?`, after)
      }
    }
    o.schema_evolution = 'auto' // for INSERT_from4 below
    // cds deploy --model-only > fills in table cds_model above
    if (o['model-only']) return o.dry && console.log(after)
    // cds deploy -- with auto schema evolution > upgrade by applying delta to former model
    creas = createsAndAlters
    drops = d
  } else {
    // cds deploy -- w/o auto schema evoution > drop-create db
    creas = cds.compile.to.sql(csn, o)
  }

  if (!drops) {
    drops = [];
    creas.forEach(each => {
        // For postgres, we add constraints via "ALTER TABLE" - so our regex might not match.
        let [, kind, entity] = each.match(/^CREATE (TABLE|VIEW) ("[^"]+"|[^\s(]+)/im) || []
        if(kind && entity)
          drops.push(`DROP ${kind} IF EXISTS ${entity};`);
      });

    drops.reverse()
  }


  if (!drops.length && !creas.length) return !o.dry

  if (o.dry) {
    console.log()
    for (let each of drops) console.log(each)
    console.log()
    for (let each of creas) console.log(each, '\n')
    return
  }

  // Set the context model while deploying for cqn42sql in new db layers
  db.model = cds.compile.for.nodejs(csn)
  await db.run(drops)
  await db.run(creas)
  return true

  async function get_prior_model() {
    let file = o['delta-from']
    if (file) {
      let prior = await cds.utils.read(file)
      return { prior: typeof prior === 'string' ? JSON.parse(prior) : prior }
    }
    if (o.dry) return {}

    let [table_exists] = await db.run(
      // REVISIT: prettier forced this horrible, unreadable formatting:
      db.kind === 'postgres'
        ? `SELECT 1 from pg_tables WHERE tablename = 'cds_model' and schemaname = current_schema()`
        : db.kind === 'sqlite'
        ? `SELECT 1 from sqlite_schema WHERE name = 'cds_model'`
        : cds.error`Schema evolution is not supported for ${db.kind} databases`,
    )

    if (o['model-only'])
      return { table_exists };

    if (table_exists) {
      let [{ csn }] = await db.run('SELECT csn from cds_model')
      return { prior: csn && JSON.parse(csn), table_exists }
    }
    return { table_exists } // no prior csn
  }
}


const { fs, path, read } = cds.utils
const { readdir } = fs.promises
const isdir = (..._) => fs.isdir(path.join(..._))
const isfile = (..._) => fs.isfile(path.join(..._))

exports.include_external_entities_in = function (model) {
  if (model._mocked) return model; else Object.defineProperty(model,'_mocked',{value:true})
  for (let each in model.definitions) {
    const def = model.definitions[each]
    if (def['@cds.persistence.mock'] === false) continue
    if (def['@cds.persistence.skip'] === true) {
      DEBUG?.('including mocked', each)
      delete def['@cds.persistence.skip']
    }
  }
  exports.exclude_external_entities_in (model)
  return model
}

exports.exclude_external_entities_in = function (csn) { // NOSONAR
  // IMPORTANT to use cds.env.requires below, not cds.requires !!
  for (let [each,{service=each,model,credentials}] of Object.entries (cds.env.requires)) {
    if (!model) continue //> not for internal services like cds.requires.odata
    if (!credentials && csn._mocked) continue //> not for mocked unbound services
    DEBUG?.('excluding external entities for', service, '...')
    const prefix = service+'.'
    for (let each in csn.definitions) if (each.startsWith(prefix)) _exclude (each)
  }
  return csn

  function _exclude (each) {
    const def = csn.definitions[each]; if (def.kind !== 'entity') return
    if (def['@cds.persistence.table'] === true) return // do not exclude replica table
    DEBUG?.('excluding external entity', each)
    def['@cds.persistence.skip'] = true
    // propagate to all views on top...
    for (let other in csn.definitions) {
      const d = csn.definitions[other]
      const p = d.query && d.query.SELECT || d.projection
      if (p && p.from.ref && p.from.ref[0] === each) _exclude (other)
    }
  }
}


exports.init = async function cds_deploy_init (db, csn=db.model, o, srces, log=()=>{}) {
  const t = cds.context?.tenant; if (t && t === cds.requires.multitenancy?.t0) return
  return db.run (async tx => {

    const m = tx.model = cds.compile.for.nodejs(csn) //> use correct model while deploying
    const data = await exports.data (m,srces)
    const query = _queries4 (db,m)
    const INSERT_from = INSERT_from4 (db,m,o)

    for await (let [ file, entity, src ] of data) {
      log (file)
      if (entity) {
        const q = INSERT_from (file) .into (entity, src)
        if (q) try { await tx.run (query(q)) } catch(e) {
          throw Object.assign (e, { message: 'in cds.deploy(): ' + e.message +'\n'+ cds.utils.inspect(q) })
        }
      } else {  //> init.js/ts case
        if (typeof src === 'function') await src(tx,csn)
      }
    }
  })
}


/** Prepare input from .csv, .json, init.js, ... */
exports.data = async function cds_deploy_prepare_data (csn, srces) {
  // In case of extension deployment .csv or .json input are provided through argument `srces`.
  if (srces) return Object.entries(srces) .map (([file, src]) => {
    let e = _entity4 (path.basename(file,'.csv'), csn)
    return [ file, e, src ]
  })
  // If not, we load them from cds.deploy.resources(csn)
  const data = []
  const resources = await exports.resources(csn, { testdata: cds.env.features.test_data })
  const resEntries = Object.entries(resources).reverse() // reversed $sources, relevant as UPSERT order
  for (const [file,e] of resEntries) {
    if (e === '*') {
      let init_js = await cds.utils._import (file)
      data.push([ file, null, init_js.default || init_js ])
    } else {
      let src = await read (file, 'utf8')
      data.push([ file, e, src ])
    }
  }
  return data
}


exports.resources = async function cds_deploy_resources (csn, opts) {
  if (!csn || !csn.definitions) csn = await cds.load (csn||'*') .then (cds.minify)
  const folders = await cds_deploy_resources.folders(csn, opts)
  const found={}, ts = process.env.CDS_TYPESCRIPT
  for (let folder of folders) {
    // fetching .csv and .json files
    for (let each of ['data','csv']) {
      const subdir = isdir(folder,each); if (!subdir) continue
      const files = await readdir (subdir)
      for (let fx of files) {
        if (fx[0] === '-') continue
        const ext = path.extname(fx); if (ext in {'.csv':1,'.json':2}) {
          const f = fx.slice(0,-ext.length)
          if (/[._]texts$/.test(f) && files.some(g => g.startsWith(f+'_'))) {
            // ignores 'Books_texts.csv/json' if there is any 'Books_texts_LANG.csv/json'
            DEBUG?.(`ignoring '${fx}' in favor of translated ones`)
            continue
          }
          const e = _entity4(f,csn); if (_skip(e)) continue
          if (cds.env.features.deploy_data_onconflict === 'replace' && !/[._]texts_/.test(f)) {
            const seenBefore = Object.entries(found).find(([_, entity]) => entity === e.name )
            if (seenBefore) {
              DEBUG?.(`Conflict for '${e.name}': replacing '${local(seenBefore[0])}' with '${local(path.join(subdir,fx))}'`)
              continue
            }
          }
          found[path.join(subdir,fx)] = e.name
        }
      }
    }
    // fetching init.js files -> Note: after .csv files to have that on top, when processing in .reverse order
    const init_js = ts && isfile(folder,'init.ts') || isfile(folder,'init.js')
    if (init_js) found[init_js] = '*'
  }
  return found
}


exports.resources.folders = async function (csn, o={}) {
  if (!csn || !csn.definitions) csn = await cds.load (csn||'*') .then (cds.minify)
  const folders = new Set (csn.$sources.map (path.dirname) .filter (f => f !== cds.home))
  if (cds.env.folders.db) folders.add (path.resolve(cds.root, cds.env.folders.db))
  if (o.testdata) folders.add (path.resolve(cds.root,'test/'))
  return folders
}


const _entity4 = (file,csn) => {
  const name = file.replace(/-/g,'.')
  const entity = csn.definitions [name]
  if (!entity) {
    if (/(.+)[._]texts_?/.test(name)) { // 'Books.texts', 'Books.texts_de'
      const base = csn.definitions [RegExp.$1]
      return base?.elements?.texts && _entity4 (base.elements.texts.target, csn)
    }
    else return DEBUG?.(`warning: ${name} not in model`)
  }
  // We also support insert into simple views if they have no projection
  const p = entity.query && entity.query.SELECT || entity.projection
  if (p && !p.columns && p.from.ref && p.from.ref.length === 1) {
    if (csn.definitions [p.from.ref[0]])  return entity
  }
  return entity.name ? entity : { name, __proto__:entity }
}


/** Prepare special handling for new db services */
const _queries4 = (db,csn) => !db.cqn2sql ? q => q : q => {
  const { columns, rows } =  q.INSERT || q.UPSERT; if (!columns) return q // REVISIT: .entries are covered by current runtime -> should eventually also be handled here
  const entity = csn.definitions[q._target.name]

  // Fill in missing primary keys...
  const { uuid } = cds.utils
  for (let k in entity.keys) if (entity.keys[k].isUUID && !columns.includes(k)) {
    columns.push(k)
    rows.forEach(row => row.push(uuid()))
  }

  // Fill in missing managed data...
  const pseudos = { $user: 'anonymous', $now: (new Date).toISOString() }
  for (let k in entity.elements) {
    const managed = entity.elements[k]['@cds.on.insert']?.['=']
    if (managed && !columns.includes(k)) {
      columns.push(k)
      rows.forEach(row => row.push(pseudos[managed]))
    }
  }

  return q
}


const INSERT_from4 = (db,m,o) => {
  const schevo = o?.schema_evolution === 'auto' || db.options.schema_evolution === 'auto'
  const INSERT_into = (schevo ? UPSERT : INSERT).into
  return (file) => ({
    '.json': { into (entity, json) {
      let records = JSON.parse(json)
      if (records.length > 0) {
        fill_ID_texts_json(records, m, entity)
        return INSERT_into(entity).entries(records)
      }
    }},
    '.csv': { into (entity, csv) {
      let [cols, ...rows] = cds.parse.csv(csv)
      if (rows.length > 0) {
        fill_ID_texts_csv(cols, rows, m, entity)
        return INSERT_into(entity).columns(cols).rows(rows)
      }
    }},
  }) [path.extname(file)]
}

const fill_ID_texts_json = (records, m, entity) => {
  const baseKey = idTextsBaseKey(m, entity)
  if (baseKey) {
    records.forEach(record => {
      if (!record.ID_texts) {
        record.ID_texts = hashedUUID(record[baseKey], record.locale)
      }
    })
  }
}

const fill_ID_texts_csv = (cols, rows, m, entity) => {
  const baseKey = idTextsBaseKey(m, entity)
  if (baseKey && !cols.find(r => r.toLowerCase() === 'id_texts')) { // and no such column in csv?
    DEBUG?.(`adding ID_texts for ${entity}`)
    const indexBaseKey = cols.findIndex(c => c.toLowerCase() === baseKey.toLowerCase())
    const indexLocale = cols.findIndex(c => c.toLowerCase() === 'locale')
    rows.forEach(row => {
      const idtexts = hashedUUID(row[indexBaseKey], row[indexLocale])
      row.push(idtexts)
    })
    cols.push('ID_texts')
  }
}

const idTextsBaseKey = (m, entity) => {
  let base
  if (m.definitions[entity]?.keys?.ID_texts  // ID_text key?
      && /(.+)[._]texts$/.test(entity) && (base = m.definitions[RegExp.$1])) { // in a .text entity?
    const baseKey = Object.keys(base.keys)[0]  // base entity's key is usually, but not always 'ID'
    return baseKey
  }
}

const hashedUUID = (...values) => {
  const sum = values.reduce((acc, curr) => acc + curr, '')
  const h = crypto.createHash('md5').update(sum).digest('hex')
  return h.slice(0, 8) + '-' + h.slice(8, 12) + '-' + h.slice(12, 16) + '-' + h.slice(16, 20) + '-' + h.slice(20)
}

const _skip = e => !e || e['@cds.persistence.skip'] === true



if (!module.parent) (async () => {
  await cds.plugins // IMPORTANT: that has to go before any call to cds.env, like through cds.deploy or cds.requires below
  let db = cds.requires.db
  try {
    let o={}, recent
    for (let each of process.argv.slice(2)) {
      if (each.startsWith('--')) o[(recent = each.slice(2))] = true
      else o[recent] = each
    }
    if (o.to) {
      db = { kind: o.to, dialect: o.to }
      if (o.url) (db.credentials ??= {}).url = o.url
      if (o.host) (db.credentials ??= {}).host = o.host
      if (o.port) (db.credentials ??= {}).port = o.port
      if (o.username) (db.credentials ??= {}).username = o.username
      if (o.password) (db.credentials ??= {}).password = o.password
    }
    db = await cds.deploy('*',o).to(db)
  } finally {
    await db?.disconnect?.()
  }
})().catch(console.error)

